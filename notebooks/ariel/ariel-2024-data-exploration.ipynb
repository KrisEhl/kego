{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import multiprocessing\n",
    "import concurrent\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import sklearn.model_selection\n",
    "import itertools\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "import mlframework.plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_COMPETITION = os.environ[\"PATH_EFOLDER\"] + \"ariel-data-challenge-2024/\"\n",
    "# FOLDER_COMPETITION = \"/kaggle/input/\"\n",
    "!ls $FOLDER_COMPETITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/kristian/Projects/mlframework/data/ariel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "train_adc_info = pd.read_csv(\n",
    "    FOLDER_COMPETITION + \"train_adc_info.csv\", index_col=\"planet_id\"\n",
    ")\n",
    "train_labels = pd.read_csv(\n",
    "    FOLDER_COMPETITION + \"train_labels.csv\", index_col=\"planet_id\"\n",
    ")\n",
    "test_adc_info = pd.read_csv(\n",
    "    FOLDER_COMPETITION + \"test_adc_info.csv\", index_col=\"planet_id\"\n",
    ")\n",
    "sample_submission = pd.read_csv(\n",
    "    FOLDER_COMPETITION + \"sample_submission.csv\", index_col=\"planet_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2))\n",
    "plt.title(\"Histogram of the planets' sizes (regression targets)\", fontsize=18)\n",
    "plt.hist(train_labels.values.ravel(), bins=20, density=True, color='olive')\n",
    "plt.xlabel(r\"Planet's size $(\\frac{r}{R})^2$\", fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.xlim(0, 0.008)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_id = 14485303\n",
    "f_signal = pd.read_parquet(FOLDER_COMPETITION + f'train/{planet_id}/FGS1_signal.parquet')\n",
    "f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_signal = f_signal.values.mean(axis=1)\n",
    "net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
    "cum_signal = net_signal.cumsum()\n",
    "window=800\n",
    "smooth_signal = (cum_signal[window:] - cum_signal[:-window]) / window\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(net_signal, label='raw net signal')\n",
    "ax1.legend()\n",
    "ax2.plot(smooth_signal, color='c', label='smoothened net signal')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('time')\n",
    "plt.suptitle('FGS1 light curve', y=0.96)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_info = train_adc_info\n",
    "planet_ids = adc_info.index\n",
    "\n",
    "dataset = 'train'\n",
    "i = 1\n",
    "\n",
    "f_signal = pd.read_parquet(FOLDER_COMPETITION + f'{dataset}/{planet_id}/FGS1_signal.parquet')\n",
    "mean_signal = f_signal.values.mean(axis=1) # mean over the 32*32 pixels\n",
    "net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
    "gain = adc_info.FGS1_adc_gain.values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase(i, planet_id, n_steps):\n",
    "    f_signal = pd.read_parquet(FOLDER_COMPETITION + f'{dataset}/{planet_id}/FGS1_signal.parquet')\n",
    "    mean_signal = f_signal.values.mean(axis=1) # mean over the 32*32 pixels\n",
    "    net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
    "    gain = adc_info.FGS1_adc_gain.values[i]\n",
    "    return [net_signal[i*n_steps:(i+1)*n_steps].mean() * gain for i in range(len(net_signal) // n_steps + 1)]\n",
    "\n",
    "def f_read_and_preprocess(dataset, adc_info, n_steps=8000):\n",
    "    \"\"\"Read the FGS1 files for all planet_ids and extract the signal.\n",
    "    \n",
    "    Parameters\n",
    "    dataset: 'train' or 'test'\n",
    "    adc_info: metadata dataframe, either train_adc_info or test_adc_info\n",
    "    \n",
    "    Returns\n",
    "    dataframe with one row per planet_id\n",
    "    \n",
    "    \"\"\"\n",
    "    planet_ids = adc_info.index\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([net_signal[i*n_steps:(i+1)*n_steps].mean() * gain for i in range(len(net_signal) // n_steps + 1)])\n",
    "    plt.show()\n",
    "\n",
    "    ids = planet_ids#[:40]\n",
    "    indices = range(len(ids))\n",
    "    print(ids)\n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()-2) as pool:\n",
    "        result = pool.apply_async(get_phase, (indices, ids, n_steps))\n",
    "    phases = result.get()\n",
    "    # with concurrent.futures.ProcessPoolExecutor() as pool:\n",
    "    #     phases = list(tqdm(pool.map(get_phase, indices, ids, itertools.repeat(n_steps)), total=len(ids)))\n",
    "    df = pd.DataFrame(\n",
    "                phases,\n",
    "                columns=[f\"phase_{i}\" for i in range(len(phases[0]))],\n",
    "                index=indices\n",
    "    )\n",
    "    filepath = f\"phases_step{n_steps}_nids{len(indices)}.csv\"\n",
    "    print(f\"... saving {filepath}\")\n",
    "    df.to_csv(filepath)\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for n_steps in [100, 400, 1000, 2000, 8000][::-1]:\n",
    "        train = f_read_and_preprocess('train', train_adc_info, n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlframework.plotting.axes_utils\n",
    "import mlframework.plotting.utils_plotting\n",
    "\n",
    "samples = range(20)\n",
    "figure, axes_grid, axes_colorbar = mlframework.plotting.utils_plotting.create_axes_grid(\n",
    "    1, len(samples)\n",
    ")\n",
    "for n_samples, sample in enumerate(samples):\n",
    "    axes = axes_grid[0, n_samples]\n",
    "    axes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels.to_numpy()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_pred[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeCV()\n",
    "train_labels_sel = train_labels.iloc[:train.shape[0]]\n",
    "oof_pred = cross_val_predict(model, train, train_labels_sel)\n",
    "\n",
    "print(f\"# R2 score: {r2_score(train_labels_sel, oof_pred):.3f}\")\n",
    "sigma_pred = mean_squared_error(train_labels_sel, oof_pred, squared=False)\n",
    "print(f\"# Root mean squared error: {sigma_pred:.6f}\")\n",
    "\n",
    "col = 1\n",
    "plt.scatter(oof_pred[:,col], train_labels_sel.iloc[:,col], s=15, c=train_adc_info.iloc[:train.shape[0]][\"star\"])\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('y_true')\n",
    "plt.title('Comparing y_true and y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9188054,
     "sourceId": 70367,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

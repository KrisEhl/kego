{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kego.plotting\n",
    "import polars as pl\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import kego.parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/mnt/e/ariel-data-challenge-2025\"\n",
    "PATH_DATA_TRAIN = os.path.join(PATH_DATA, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANET_ID = 1010375142\n",
    "# signal_f = pl.read_parquet(\"~/Downloads/FGS1_signal_0_1010375142.parquet\")\n",
    "# signal_c = pl.read_parquet(\"~/Downloads/AIRS-CH0_signal_0_1010375142.parquet\")\n",
    "# train = pl.read_csv(\"~/Downloads/train.csv\")\n",
    "# train_info = pl.read_csv(\"~/Downloads/train_star_info.csv\")\n",
    "signal_f = pl.read_parquet(\n",
    "    f\"{PATH_DATA_TRAIN}/{PLANET_ID}/FGS1_signal_0.parquet\"\n",
    ")\n",
    "signal_c = pl.read_parquet(\n",
    "    f\"{PATH_DATA_TRAIN}/{PLANET_ID}/AIRS-CH0_signal_0.parquet\"\n",
    ")\n",
    "train = pl.read_csv(f\"{PATH_DATA}/train.csv\")\n",
    "wavelengths = pl.read_csv(f\"{PATH_DATA}/wavelengths.csv\")\n",
    "train_info = pl.read_csv(f\"{PATH_DATA}/train_star_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile f_read_and_preprocess.py\n",
    "\n",
    "def process_planet(planet_id, path_planets):\n",
    "    f_signal = pl.read_parquet(f'{path_planets}/{planet_id}/FGS1_signal_0.parquet')\n",
    "    mean_signal = f_signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / 1024 # mean over the 32*32 pixels\n",
    "    net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
    "    return net_signal\n",
    "\n",
    "def f_read_and_preprocess(dataset, adc_info, planet_ids):\n",
    "    \"\"\"Read the FGS1 files for all planet_ids and extract the time series.\n",
    "    \n",
    "    Parameters\n",
    "    dataset: 'train' or 'test'\n",
    "    adc_info: metadata dataframe, either train_adc_info or test_adc_info\n",
    "    planet_ids: list of planet ids\n",
    "    \n",
    "    Returns\n",
    "    dataframe with one row per planet_id and 67500 values per row\n",
    "    \n",
    "    \"\"\"\n",
    "    # f_raw_train = np.full((len(planet_ids), 67500), np.nan, dtype=np.float32)\n",
    "    path_planets = f\"{PATH_DATA}/{dataset}\"\n",
    "    net_signals = kego.parallelize.parallelize(function=process_planet, args_zipped=((planet_id, path_planets) for planet_id in planet_ids))\n",
    "    return net_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "exec(open(\"f_read_and_preprocess.py\", \"r\").read())\n",
    "f_raw_train = f_read_and_preprocess(\"train\", train_info, train[\"planet_id\"])\n",
    "with open(\"f_raw_train.pickle\", \"wb\") as f:\n",
    "    pickle.dump(f_raw_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

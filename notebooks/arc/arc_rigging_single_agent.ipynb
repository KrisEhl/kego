{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rigging as rg\n",
    "import mlframework.arc.images as images\n",
    "from mlframework.files.json import load_json\n",
    "import arckit\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = pathlib.Path(\"/home/kristian/Projects/mlframework/data/\")\n",
    "PATH_COMPETITION = PATH_DATA / \"arc/arc-prize-2024/\"\n",
    "PATH_TRAIN_CHALLENGES = PATH_COMPETITION / \"arc-agi_training_challenges.json\"\n",
    "PATH_TRAIN_SOLUTIONS = PATH_COMPETITION / \"arc-agi_training_solutions.json\"\n",
    "PATH_TEST = PATH_COMPETITION / \"test.csv\"\n",
    "PATH_SUBMISSION_EXAMPLE = PATH_COMPETITION / \"sample_submission.csv\"\n",
    "\n",
    "# MODEL = \"transformers!meta-llama/Meta-Llama-3-8B-Instruct,device_map=cuda:1,max_tokens=1024,load_in_4bit=True\"\n",
    "MODEL = \"openai/gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_solutions = load_json(PATH_TRAIN_SOLUTIONS)\n",
    "\n",
    "train_set, test_set = arckit.load_data(\"kaggle2024\")\n",
    "\n",
    "task_example = train_set.tasks[0]\n",
    "drawing = images.show_task(task_example, train_solutions=train_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = task_example.gpt_prompt(0, include_completion=False)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_str(array):\n",
    "    return array.__str__().strip(\"[]\").replace(\"]\", \"\\n\").replace(\"[\", \"\").replace(\",\", \"\")\n",
    "def sample_to_str(sample):\n",
    "    examples_dict = sample.to_dict()\n",
    "    training_examples_str = \"\"\n",
    "    for i, example in enumerate(examples_dict[\"train\"]):\n",
    "        for io in [\"input\", \"output\"]:\n",
    "            training_examples_str += f\"{io} {i}: \" + array_to_str(example[io]) + \"\\n\"\n",
    "    return training_examples_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution(rg.Model):\n",
    "    solution: str\n",
    "    explanation: str\n",
    "\n",
    "def get_model():\n",
    "    return rg.get_generator(MODEL)\n",
    "\n",
    "async def generate_solution(sample, model, verbose=False):\n",
    "    system_prompt = \"\"\"\n",
    "        'We are playing a game which involves transforming an input grid of digits into an output grid of digits. \n",
    "        In general, digits form objects in 2D and the task is to perform some spatial transformation \n",
    "        of these objects to go from the input grid to the output grid. \n",
    "        All the information about the transformation is contained within the input pairs themselves, \n",
    "        and your answer will only be correct if the output grid is exactly correct, \n",
    "        so this is what I expect from you. I will begin by giving you several examples of input-output pairs. \n",
    "        You will then be given a new input grid, and you must provide the corresponding output grid.\\n\n",
    "        \n",
    "        Please provide a step-by-step explanation. \n",
    "        Specifically, answer the following in your explanation. \n",
    "        1. Justify the output shape of your answer. \\n\n",
    "        2. Did you consider shapes in the outputs and why?\\n\n",
    "        Provide the output for Input 6 again at the end of your answer.'\n",
    "    \"\"\"\n",
    "    sample_str = sample_to_str(sample)\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        The training sample is {sample_str}\n",
    "    \n",
    "        Provide your solution and explanation within the tag {Solution.xml_tags()}.\n",
    "    \"\"\"\n",
    "    asker = (\n",
    "        await model\n",
    "        .chat(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ]\n",
    "        )\n",
    "        .run()\n",
    "    )\n",
    "    solution = asker.last.parse(Solution).solution\n",
    "    explanation = asker.last.parse(Solution).explanation\n",
    "    if verbose:\n",
    "        print(f\"=== Solution ====\")\n",
    "        print(solution)\n",
    "        print(f\"=== Explanation ====\")\n",
    "        print(explanation)\n",
    "\n",
    "    return solution, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await generate_solution(sample=task_example, model=model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

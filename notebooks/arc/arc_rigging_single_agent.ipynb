{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rigging as rg\n",
    "import mlframework.arc.images as images\n",
    "from mlframework.files.json import load_json\n",
    "import arckit\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = pathlib.Path(\"/home/kristian/Projects/mlframework/data/\")\n",
    "PATH_COMPETITION = PATH_DATA / \"arc/arc-prize-2024/\"\n",
    "PATH_TRAIN_CHALLENGES = PATH_COMPETITION / \"arc-agi_training_challenges.json\"\n",
    "PATH_TRAIN_SOLUTIONS = PATH_COMPETITION / \"arc-agi_training_solutions.json\"\n",
    "PATH_TEST = PATH_COMPETITION / \"test.csv\"\n",
    "PATH_SUBMISSION_EXAMPLE = PATH_COMPETITION / \"sample_submission.csv\"\n",
    "\n",
    "MODEL = \"transformers!meta-llama/Meta-Llama-3-8B-Instruct,device_map=cuda:1,max_tokens=1024,load_in_4bit=True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_solutions = load_json(PATH_TRAIN_SOLUTIONS)\n",
    "\n",
    "train_set, test_set = arckit.load_data(\"kaggle2024\")\n",
    "\n",
    "task_example = train_set.tasks[0]\n",
    "drawing = images.show_task(task_example, train_solutions=train_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = task_example.gpt_prompt(0, include_completion=False)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AskerQuestion(rg.Model):\n",
    "    question: str\n",
    "\n",
    "def get_model():\n",
    "    return rg.get_generator(MODEL)\n",
    "\n",
    "async def ask_next_question(system_prompt, model, verbose=False):\n",
    "    system_prompt = \"\"\"\n",
    "        'We are playing a game which involves transforming an input grid of digits into an output grid of digits. \n",
    "        In general, digits form objects in 2D and the task is to perform some spatial transformation \n",
    "        of these objects to go from the input grid to the output grid. \n",
    "        All the information about the transformation is contained within the input pairs themselves, \n",
    "        and your answer will only be correct if the output grid is exactly correct, \n",
    "        so this is what I expect from you. I will begin by giving you several examples of input-output pairs. \n",
    "        You will then be given a new input grid, and you must provide the corresponding output grid.\\n\n",
    "        \n",
    "        Input 1: \\n0 7 7\\n7 7 7\\n0 7 7\\nOutput 1: \\n0 0 0 0 7 7 0 7 7\\n0 0 0 7 7 7 7 7 7\\n0 0 0 0 7 7 0 7 7\\n0 7 7 0 7 7 0 7 7\\n7 7 7 7 7 7 7 7 7\\n0 7 7 0 7 7 0 7 7\\n0 0 0 0 7 7 0 7 7\\n0 0 0 7 7 7 7 7 7\\n0 0 0 0 7 7 0 7 7\\n\\nInput 2: \\n4 0 4\\n0 0 0\\n0 4 0\\nOutput 2: \\n4 0 4 0 0 0 4 0 4\\n0 0 0 0 0 0 0 0 0\\n0 4 0 0 0 0 0 4 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 4 0 4 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 4 0 0 0 0\\n\\nInput 3: \\n0 0 0\\n0 0 2\\n2 0 2\\nOutput 3: \\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 2\\n0 0 0 0 0 0 2 0 2\\n0 0 0 0 0 0 0 0 0\\n0 0 2 0 0 0 0 0 2\\n2 0 2 0 0 0 2 0 2\\n\\nInput 4: \\n6 6 0\\n6 0 0\\n0 6 6\\nOutput 4: \\n6 6 0 6 6 0 0 0 0\\n6 0 0 6 0 0 0 0 0\\n0 6 6 0 6 6 0 0 0\\n6 6 0 0 0 0 0 0 0\\n6 0 0 0 0 0 0 0 0\\n0 6 6 0 0 0 0 0 0\\n0 0 0 6 6 0 6 6 0\\n0 0 0 6 0 0 6 0 0\\n0 0 0 0 6 6 0 6 6\\n\\nInput 5: \\n2 2 2\\n0 0 0\\n0 2 2\\nOutput 5: \\n2 2 2 2 2 2 2 2 2\\n0 0 0 0 0 0 0 0 0\\n0 2 2 0 2 2 0 2 2\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0\\n0 0 0 2 2 2 2 2 2\\n0 0 0 0 0 0 0 0 0\\n0 0 0 0 2 2 0 2 2\\n\\nInput 6:\\n7 0 7\\n7 0 7\\n7 7 0Please provide a step-by-step explanation. Specifically, answer the following in your explanation. 1. Justify the output shape of your answer. \\n2. Did you consider shapes in the outputs and why?\\nProvide the output for Input 6 again at the end of your answer.'\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        Previous questions and answers are:\n",
    "            {prev_content}\n",
    "        \n",
    "        Ask your question within the tag {AskerQuestion.xml_tags()}\n",
    "    \"\"\"\n",
    "    asker = (\n",
    "        await model\n",
    "        .chat(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ]\n",
    "        )\n",
    "        .run()\n",
    "    )\n",
    "    question = asker.last.parse(AskerQuestion).question\n",
    "    if verbose:\n",
    "        print(f\"=== Question {len(questions) + 1} ====\")\n",
    "        print(question)\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
